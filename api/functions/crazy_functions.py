
# ä¸»æµç¨‹å‡½æ•°
def analyze_project(self,project_folder: str, output_folder: str)->str:
    """
    Analyze all Python files in the specified directory and provide a summary.

    Args:
        self (Agent): The agent instance calling the function.
        project_folder (str): The path to the directory containing Python files to be analyzed.
        output_folder (str):The path of output file.

    Returns:
        str: A summary analysis result for the entire project. 
    """
    import os
    import json
    import threading
    from concurrent.futures import ThreadPoolExecutor
    from typing import List, Dict  
    # å•æ–‡ä»¶åˆ†æä»»åŠ¡
    MERMAID_TEMPLATE = r"""
```mermaid
flowchart LR
    %% <gpt_academic_hide_mermaid_code> ä¸€ä¸ªç‰¹æ®Šæ ‡è®°ï¼Œç”¨äºåœ¨ç”Ÿæˆmermaidå›¾è¡¨æ—¶éšè—ä»£ç å—
    classDef Comment stroke-dasharray: 5 5
    subgraph {graph_name}
{relationship}
    end
```
"""
    def analyze_single_file(file_path: str) -> Dict:
        import os
        import json
        import threading
        from concurrent.futures import ThreadPoolExecutor
        from typing import List, Dict  
        """ä½¿ç”¨ LLM åˆ†æå•ä¸ªæ–‡ä»¶"""
        with open(file_path, "r", encoding="utf-8") as file:
            file_content = file.read()

        # æ„é€ æ¶ˆæ¯æ ¼å¼
        messages = [
    {"role": "system", "content": "You are a software architecture analyst analyzing a source code project. Your responses must be clear and concise."},
    {"role": "user", "content": f"Please provide an overview of the following program file. The file name is {file_path}, and the file content is {file_content}"}
]


        # è°ƒç”¨ API å¹¶è¿”å›ç»“æœ
        response = llm_client.generate_response(messages)
        return {
            "file": file_path,
            "analysis": response["content"]
        }

    def indent(text, prefix, predicate=None):
        import os
        import json
        import threading
        from concurrent.futures import ThreadPoolExecutor
        from typing import List, Dict  
        """Adds 'prefix' to the beginning of selected lines in 'text'.

        If 'predicate' is provided, 'prefix' will only be added to the lines
        where 'predicate(line)' is True. If 'predicate' is not provided,
        it will default to adding 'prefix' to all non-empty lines that do not
        consist solely of whitespace characters.
        """
        if predicate is None:
            def predicate(line):
                return line.strip()

        def prefixed_lines():
            for line in text.splitlines(True):
                yield (prefix + line if predicate(line) else line)
        return ''.join(prefixed_lines())

    def build_file_tree_mermaid_diagram(file_manifest, file_comments, graph_name):
        import os
        import json
        import threading
        from concurrent.futures import ThreadPoolExecutor
        from typing import List, Dict  
        class FileNode:
            def __init__(self, name):
                self.name = name
                self.children = []
                self.is_leaf = False
                self.level = 0
                self.parenting_ship = []
                self.comment = ""
                self.comment_maxlen_show = 50

            @staticmethod
            def add_linebreaks_at_spaces(string, interval=10):
                return '\n'.join(string[i:i+interval] for i in range(0, len(string), interval))

            def sanitize_comment(self, comment):
                if len(comment) > self.comment_maxlen_show: suf = '...'
                else: suf = ''
                comment = comment[:self.comment_maxlen_show]
                comment = comment.replace('\"', '').replace('`', '').replace('\n', '').replace('`', '').replace('$', '')
                comment = self.add_linebreaks_at_spaces(comment, 10)
                return '`' + comment + suf + '`'

            def add_file(self, file_path, file_comment):
                directory_names, file_name = os.path.split(file_path)
                current_node = self
                level = 1
                if directory_names == "":
                    new_node = FileNode(file_name)
                    current_node.children.append(new_node)
                    new_node.is_leaf = True
                    new_node.comment = self.sanitize_comment(file_comment)
                    new_node.level = level
                    current_node = new_node
                else:
                    dnamesplit = directory_names.split(os.sep)
                    for i, directory_name in enumerate(dnamesplit):
                        found_child = False
                        level += 1
                        for child in current_node.children:
                            if child.name == directory_name:
                                current_node = child
                                found_child = True
                                break
                        if not found_child:
                            new_node = FileNode(directory_name)
                            current_node.children.append(new_node)
                            new_node.level = level - 1
                            current_node = new_node
                    term = FileNode(file_name)
                    term.level = level
                    term.comment = self.sanitize_comment(file_comment)
                    term.is_leaf = True
                    current_node.children.append(term)

            def print_files_recursively(self, level=0, code="R0"):
                print('    '*level + self.name + ' ' + str(self.is_leaf) + ' ' + str(self.level))
                for j, child in enumerate(self.children):
                    child.print_files_recursively(level=level+1, code=code+str(j))
                    self.parenting_ship.extend(child.parenting_ship)
                    p1 = f"""{code}[\"ğŸ—{self.name}\"]""" if self.is_leaf else f"""{code}[[\"ğŸ“{self.name}\"]]"""
                    p2 = """ --> """
                    p3 = f"""{code+str(j)}[\"ğŸ—{child.name}\"]""" if child.is_leaf else f"""{code+str(j)}[[\"ğŸ“{child.name}\"]]"""
                    edge_code = p1 + p2 + p3
                    if edge_code in self.parenting_ship:
                        continue
                    self.parenting_ship.append(edge_code)
                if self.comment != "":
                    pc1 = f"""{code}[\"ğŸ—{self.name}\"]""" if self.is_leaf else f"""{code}[[\"ğŸ“{self.name}\"]]"""
                    pc2 = f""" -.-x """
                    pc3 = f"""C{code}[\"{self.comment}\"]:::Comment"""
                    edge_code = pc1 + pc2 + pc3
                    self.parenting_ship.append(edge_code)

        # Create the root node
        file_tree_struct = FileNode("root")
        # Build the tree structure
        for file_path, file_comment in zip(file_manifest, file_comments):
            file_tree_struct.add_file(file_path, file_comment)
        file_tree_struct.print_files_recursively()
        cc = "\n".join(file_tree_struct.parenting_ship)
        ccc = indent(cc, prefix=" "*8)
        return MERMAID_TEMPLATE.format(graph_name=graph_name, relationship=ccc)
    # è¾“å…¥å¤„ç†
    def get_file_manifest(project_folder: str) -> List[str]:
        import os
        import json
        import threading
        from concurrent.futures import ThreadPoolExecutor
        from typing import List, Dict    
        """è·å–ç›®å½•ä¸‹çš„ Python æ–‡ä»¶åˆ—è¡¨"""
        if not os.path.exists(project_folder):
            raise FileNotFoundError(f"filepath {project_folder} not exist!")

        file_manifest = []
        for root, _, files in os.walk(project_folder):
            for file in files:
                if file.endswith(".py"):
                    file_manifest.append(os.path.join(root, file))
        if not file_manifest:
            raise FileNotFoundError("no Python file!")

        if len(file_manifest) > 512:
            raise ValueError("over 512!")
        return file_manifest
# å¤šçº¿ç¨‹é€æ–‡ä»¶åˆ†æ
    def analyze_files_multithread(file_manifest: List[str]) -> List[Dict]:
        import os
        import json
        import threading
        from concurrent.futures import ThreadPoolExecutor
        from typing import List, Dict  
        """å¤šçº¿ç¨‹åˆ†ææ–‡ä»¶"""
        results = []
        with ThreadPoolExecutor(max_workers=8) as executor:
            futures = {executor.submit(analyze_single_file, file): file for file in file_manifest}
            for future in futures:
                try:
                    results.append(future.result())
                except Exception as e:
                    print(f"error when analyzing {futures[future]} : {e}")
        return results
    
    class LLMClient:
        def __init__(self, base_url: str, api_key: str, model: str):
            from openai import OpenAI
            self.client = OpenAI(base_url=base_url, api_key=api_key)
            self.model = model

        def generate_response(self, messages: List[Dict[str, str]]) -> Dict:
            """
            è°ƒç”¨ Sambanova LLM API ç”Ÿæˆå“åº”ã€‚
            :param messages: æ¶ˆæ¯åˆ—è¡¨ï¼ŒåŒ…å« role å’Œ content é”®ã€‚
            :return: LLM çš„ç”Ÿæˆç»“æœï¼ŒåŒ…å«ç”Ÿæˆçš„å†…å®¹å’Œä½¿ç”¨æƒ…å†µã€‚
            """
            try:
                # è°ƒç”¨ API ç”Ÿæˆå“åº”
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages
                )

                # æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«ç”Ÿæˆçš„å†…å®¹
                if hasattr(response, 'choices') and len(response.choices) > 0:
                    message_content = response.choices[0].message.content
                    # usage_info = response.usage if hasattr(response, 'usage') else {}
                    return {
                        "content": message_content
                    }
                else:
                    raise ValueError("No content generated in the response!")

            except Exception as e:
                print(f"Error occurred while calling the API: {e}")
                return {"content": "Call failed, please check the input or service status.", "usage": {}}

    llm_client = LLMClient(
            base_url="https://api.sambanova.ai/v1",
            api_key="614e1948-9d06-4764-8124-9cad201c8281",
            model="Meta-Llama-3.1-8B-Instruct"
        )
    # Step 1: è·å–æ–‡ä»¶æ¸…å•
    file_manifest = get_file_manifest(project_folder)
    print(f"å‘ç° {len(file_manifest)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹åˆ†æ...")

    # Step 2: å¤šçº¿ç¨‹é€æ–‡ä»¶åˆ†æ
    analysis_results = analyze_files_multithread(file_manifest)
    print("é€æ–‡ä»¶åˆ†æå®Œæˆï¼Œä¿å­˜ä¸­é—´ç»“æœ...")
    with open(os.path.join(output_folder, "file_analysis.json"), "w", encoding="utf-8") as f:
        json.dump(analysis_results, f, ensure_ascii=False, indent=4)
    # æ‰¹é‡æ±‡æ€»åˆ†æ
    def summarize_files_in_batches(analysis_results: List[Dict], batch_size: int = 16) -> List[Dict]:
        import os
        import json
        import threading
        from concurrent.futures import ThreadPoolExecutor
        from typing import List, Dict  
        """æŒ‰æ‰¹æ¬¡æ±‡æ€»æ–‡ä»¶åˆ†æç»“æœ"""
        summaries = []
        for i in range(0, len(analysis_results), batch_size):
            batch = analysis_results[i:i + batch_size]
            file_descriptions = "\n".join([f"{res['file']}: {res['analysis']}" for res in batch])

            # æ„é€ æ¶ˆæ¯æ ¼å¼
            messages = [
    {"role": "system", "content": "You are a software architecture analyst, analyzing the source code of a project."},
    {"role": "user", "content": f"Briefly describe the functionality of the following files using a Markdown table:\n{file_descriptions}\nBased on the above analysis, summarize the overall functionality of the program in one sentence."}
]


            # è°ƒç”¨ API å¹¶ä¿å­˜ç»“æœ
            response = llm_client.generate_response(messages)
            summaries.append({
                "batch_start": i,
                "batch_end": i + batch_size,
                "summary": response["content"]
            })
        return summaries
    # å¯è§†åŒ–æ–‡ä»¶æ ‘
    def generate_file_tree_diagram(project_folder: str, file_manifest: List[str], file_comments: List[str]) -> str:
        import os
        import json
        import threading
        from concurrent.futures import ThreadPoolExecutor
        from typing import List, Dict  
        """
        ç”Ÿæˆé¡¹ç›®æ–‡ä»¶æ ‘çš„ Mermaid.js å›¾è¡¨ã€‚
        :param project_folder: é¡¹ç›®æ ¹ç›®å½•ã€‚
        :param file_manifest: æ–‡ä»¶è·¯å¾„åˆ—è¡¨ã€‚
        :param file_comments: å¯¹åº”æ–‡ä»¶çš„è¯„è®ºæˆ–åˆ†æã€‚
        :return: Mermaid.js æ ¼å¼çš„æ–‡ä»¶æ ‘å›¾è¡¨ã€‚
        """
        graph_name = "é¡¹ç›®æ–‡ä»¶æ ‘"
        diagram_code = build_file_tree_mermaid_diagram(file_manifest, file_comments, graph_name)
        return diagram_code

    # Step 3: æ‰¹é‡æ±‡æ€»åˆ†æ
    summaries = summarize_files_in_batches(analysis_results)
    print("æ±‡æ€»åˆ†æå®Œæˆï¼Œä¿å­˜ç»“æœ...")
    with open(os.path.join(output_folder, "summary_analysis.json"), "w", encoding="utf-8") as f:
        json.dump(summaries, f, ensure_ascii=False, indent=4)

    # æå–æ±‡æ€»å†…å®¹ä¸º Markdown è¡¨æ ¼
    markdown_summary = "| File | Analysis |\n| --- | --- |\n"
    for result in analysis_results:
        markdown_summary += f"| {os.path.basename(result['file'])} | {result['analysis']} |\n"

    # Step 4: ç”Ÿæˆæ–‡ä»¶æ ‘å¯è§†åŒ–
    # ä»åˆ†æç»“æœä¸­æå–æ–‡ä»¶æ³¨é‡Šï¼ˆåˆ†æå†…å®¹ï¼‰
    file_comments = [result["analysis"] for result in analysis_results]
    file_tree_diagram = generate_file_tree_diagram(project_folder, file_manifest, file_comments)
    with open(os.path.join(output_folder, "file_tree.md"), "w", encoding="utf-8") as f:
        f.write(file_tree_diagram)

    return (
            f"Analysis complete! The result has been saved to {output_folder}\n\n"
            f"### File Tree:\n{file_tree_diagram}\n\n"
            f"### File Analysis Summary:\n{markdown_summary}"
            f"è¯·ä»¥markdownæ ¼å¼å±•ç°File Analysis Summary"
            )

